{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from notion_client import Client\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "class NotionProcessor:\n",
    "    def __init__(self, auth_token: str):\n",
    "        \"\"\"Initialize the Notion client with authentication token.\"\"\"\n",
    "        self.notion = Client(auth=auth_token)\n",
    "    \n",
    "    def get_database_pages(self, database_id: str, parent_properties: Dict = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve all pages from a Notion database.\n",
    "        If parent_properties provided, merge them with each page's properties.\n",
    "        \"\"\"\n",
    "        pages = []\n",
    "        cursor = None\n",
    "        \n",
    "        while True:\n",
    "            response = self.notion.databases.query(\n",
    "                database_id=database_id,\n",
    "                start_cursor=cursor\n",
    "            )\n",
    "            \n",
    "            # If parent properties exist, merge them with each page\n",
    "            if parent_properties:\n",
    "                for page in response['results']:\n",
    "                    self._merge_parent_properties(page, parent_properties)\n",
    "            \n",
    "            pages.extend(response['results'])\n",
    "            \n",
    "            if not response.get('has_more'):\n",
    "                break\n",
    "                \n",
    "            cursor = response['next_cursor']\n",
    "            \n",
    "        return pages\n",
    "    \n",
    "    def _merge_parent_properties(self, page: Dict, parent_properties: Dict):\n",
    "        \"\"\"Merge parent properties into page properties, avoiding duplicates.\"\"\"\n",
    "        for key, value in parent_properties.items():\n",
    "            if key not in page['properties']:\n",
    "                # Create a new property of type 'rich_text' to store inherited values\n",
    "                page['properties'][f'parent_{key}'] = {\n",
    "                    'type': 'rich_text',\n",
    "                    'rich_text': [{\n",
    "                        'type': 'text',\n",
    "                        'text': {'content': str(value)},\n",
    "                        'plain_text': str(value)\n",
    "                    }]\n",
    "                }\n",
    "    \n",
    "    def extract_properties(self, page: Dict) -> Dict:\n",
    "        \"\"\"Extract properties from a page.\"\"\"\n",
    "        properties = {}\n",
    "        \n",
    "        for prop_name, prop_data in page['properties'].items():\n",
    "            prop_type = prop_data['type']\n",
    "            \n",
    "            if prop_type == 'title':\n",
    "                properties[prop_name] = self._get_rich_text_content(prop_data['title'])\n",
    "            elif prop_type == 'rich_text':\n",
    "                properties[prop_name] = self._get_rich_text_content(prop_data['rich_text'])\n",
    "            elif prop_type == 'select':\n",
    "                if prop_data['select']:\n",
    "                    properties[prop_name] = prop_data['select']['name']\n",
    "            elif prop_type == 'multi_select':\n",
    "                properties[prop_name] = [item['name'] for item in prop_data['multi_select']]\n",
    "            elif prop_type == 'date':\n",
    "                if prop_data['date']:\n",
    "                    properties[prop_name] = prop_data['date']['start']\n",
    "            elif prop_type in ['number', 'checkbox']:\n",
    "                properties[prop_name] = prop_data[prop_type]\n",
    "                \n",
    "        return properties\n",
    "    \n",
    "    def _get_rich_text_content(self, rich_text: List) -> str:\n",
    "        \"\"\"Extract text content from rich text array.\"\"\"\n",
    "        return ' '.join([text['plain_text'] for text in rich_text if text.get('plain_text')])\n",
    "    \n",
    "    def get_block_children(self, block_id: str, level: int = 0) -> List[Tuple[Dict, int]]:\n",
    "        \"\"\"Retrieve all child blocks of a given block with their nesting level.\"\"\"\n",
    "        blocks = []\n",
    "        cursor = None\n",
    "        \n",
    "        while True:\n",
    "            response = self.notion.blocks.children.list(\n",
    "                block_id=block_id,\n",
    "                start_cursor=cursor\n",
    "            )\n",
    "            \n",
    "            for block in response['results']:\n",
    "                blocks.append((block, level))\n",
    "                \n",
    "                if block.get('has_children'):\n",
    "                    # For child database blocks, don't process them here\n",
    "                    if block['type'] != 'child_database':\n",
    "                        child_blocks = self.get_block_children(block['id'], level + 1)\n",
    "                        blocks.extend(child_blocks)\n",
    "            \n",
    "            if not response.get('has_more'):\n",
    "                break\n",
    "                \n",
    "            cursor = response['next_cursor']\n",
    "            \n",
    "        return blocks\n",
    "    \n",
    "    def process_blocks(self, blocks: List[Tuple[Dict, int]]) -> Tuple[Dict, List[str]]:\n",
    "        \"\"\"\n",
    "        Process blocks to extract headers (with sub-headers) and content.\n",
    "        Returns tuple of (headers_dict, content_sections).\n",
    "        \"\"\"\n",
    "        current_main_header = None\n",
    "        current_sub_headers = []\n",
    "        current_content = []\n",
    "        headers = {}\n",
    "        content_sections = []\n",
    "        current_bullet_group = []\n",
    "        \n",
    "        def save_current_section():\n",
    "            \"\"\"Helper function to save current section's content.\"\"\"\n",
    "            nonlocal current_content, current_bullet_group, content_sections, current_main_header, current_sub_headers, headers\n",
    "            \n",
    "            # Save any remaining bullet group\n",
    "            if current_bullet_group:\n",
    "                current_content.append(self._merge_bullet_group(current_bullet_group))\n",
    "                current_bullet_group = []\n",
    "            \n",
    "            # Save content if exists and we have a header\n",
    "            if current_main_header is not None and current_content:\n",
    "                content_sections.append('\\n'.join(filter(None, current_content)))\n",
    "                full_header = current_main_header\n",
    "                if current_sub_headers:\n",
    "                    full_header += ' - ' + ' - '.join(current_sub_headers)\n",
    "                headers[full_header] = len(content_sections) - 1  # Point to the section we just added\n",
    "        \n",
    "        for block, level in blocks:\n",
    "            block_type = block['type']\n",
    "            \n",
    "            # Handle headers\n",
    "            if block_type.startswith('heading_'):\n",
    "                # Save current section before starting new one\n",
    "                save_current_section()\n",
    "                \n",
    "                # Reset content collection for new section\n",
    "                current_content = []\n",
    "                current_bullet_group = []\n",
    "                \n",
    "                # Process new header\n",
    "                header_text = self._get_rich_text_content(block[block_type]['rich_text'])\n",
    "                header_level = int(block_type[-1])\n",
    "                \n",
    "                if header_level == 1:\n",
    "                    current_main_header = header_text\n",
    "                    current_sub_headers = []\n",
    "                else:\n",
    "                    current_sub_headers.append(header_text)\n",
    "            \n",
    "            # Handle child database\n",
    "            elif block_type == 'child_database':\n",
    "                if current_bullet_group:\n",
    "                    current_content.append(self._merge_bullet_group(current_bullet_group))\n",
    "                    current_bullet_group = []\n",
    "                current_content.append(f\"[Database: {block['id']}]\")\n",
    "            \n",
    "            # Handle bullet points and numbered lists\n",
    "            elif block_type in ['bulleted_list_item', 'numbered_list_item']:\n",
    "                text_content = self._get_rich_text_content(block[block_type]['rich_text'])\n",
    "                \n",
    "                if level == 0:\n",
    "                    if current_bullet_group:\n",
    "                        current_content.append(self._merge_bullet_group(current_bullet_group))\n",
    "                        current_bullet_group = []\n",
    "                    current_bullet_group = [(text_content, level)]\n",
    "                else:\n",
    "                    current_bullet_group.append((text_content, level))\n",
    "            \n",
    "            # Handle regular paragraphs\n",
    "            elif block_type == 'paragraph':\n",
    "                if current_bullet_group:\n",
    "                    current_content.append(self._merge_bullet_group(current_bullet_group))\n",
    "                    current_bullet_group = []\n",
    "                \n",
    "                text_content = self._get_rich_text_content(block[block_type]['rich_text'])\n",
    "                if text_content:\n",
    "                    current_content.append(text_content)\n",
    "        \n",
    "        # Save final section\n",
    "        save_current_section()\n",
    "        \n",
    "        return headers, content_sections\n",
    "    \n",
    "    def _merge_bullet_group(self, bullet_group: List[Tuple[str, int]]) -> str:\n",
    "        \"\"\"Merge a group of bullets into a single line, with sub-bullets inline.\"\"\"\n",
    "        if not bullet_group:\n",
    "            return \"\"\n",
    "        \n",
    "        result = []\n",
    "        current_main_bullet = []\n",
    "        \n",
    "        for text, level in bullet_group:\n",
    "            if level == 0:\n",
    "                if current_main_bullet:\n",
    "                    result.append(' '.join(current_main_bullet))\n",
    "                current_main_bullet = [text]\n",
    "            else:\n",
    "                current_main_bullet.append(text)\n",
    "        \n",
    "        if current_main_bullet:\n",
    "            result.append(' '.join(current_main_bullet))\n",
    "        \n",
    "        return '\\n'.join(result)\n",
    "    \n",
    "    def process_page(self, page: Dict, parent_properties: Dict = None) -> List[Dict]:\n",
    "        \"\"\"Process a single page and its nested databases.\"\"\"\n",
    "        results = []\n",
    "        properties = self.extract_properties(page)\n",
    "        \n",
    "        # Merge parent properties if they exist\n",
    "        if parent_properties:\n",
    "            properties.update({f'parent_{k}': v for k, v in parent_properties.items()})\n",
    "        \n",
    "        # Process page blocks\n",
    "        blocks = self.get_block_children(page['id'])\n",
    "        headers, content_sections = self.process_blocks(blocks)\n",
    "        \n",
    "        # Add headers to properties and create entries\n",
    "        for header, section_index in headers.items():\n",
    "            section_properties = properties.copy()\n",
    "            section_properties['header'] = header\n",
    "            \n",
    "            # Create entry for this section\n",
    "            if 0 <= section_index < len(content_sections):\n",
    "                results.append({\n",
    "                    'properties': section_properties,\n",
    "                    'content': content_sections[section_index]\n",
    "                })\n",
    "        \n",
    "        # Process any child databases found in the blocks\n",
    "        for block, _ in blocks:\n",
    "            if block['type'] == 'child_database':\n",
    "                child_pages = self.get_database_pages(block['id'], properties)\n",
    "                for child_page in child_pages:\n",
    "                    results.extend(self.process_page(child_page, properties))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def process_database(self, database_id: str) -> List[Dict]:\n",
    "        \"\"\"Process entire database and return structured data.\"\"\"\n",
    "        processed_data = []\n",
    "        \n",
    "        # Get all pages from the database\n",
    "        pages = self.get_database_pages(database_id)\n",
    "        \n",
    "        # Process each page and its nested databases\n",
    "        for page in pages:\n",
    "            processed_data.extend(self.process_page(page))\n",
    "            \n",
    "        return processed_data\n",
    "\n",
    "# Example usage in Jupyter notebook (separate cells):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in Jupyter notebook (separate cells):\n",
    "\n",
    "# Cell 1: Initialize processor\n",
    "NOTION_TOKEN = os.getenv(\"NOTION_TOKEN\")\n",
    "DATABASE_ID = os.getenv(\"NOTION_DATABASE_ID\")\n",
    "\n",
    "processor = NotionProcessor(NOTION_TOKEN)\n",
    "processed_data = processor.process_database(DATABASE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The  Boundary Diagram Tool (BDT)  is an advanced tool designed for  change impact analysis  in large-scale Simulink models, particularly those used in embedded systems like automotive control units. The tool enables engineers to trace how changes in specific parts of a system propagate through other models and network interfaces, aiding in software maintenance, debugging, and ensuring compliance with safety standards like  ISO 26262 . It was developed as part of a collaboration with  Stellantis  (formerly FCA), where it played a key role in managing changes within complex automotive systems, such as  hybrid electric vehicle control systems .\\nAs part of the development team, my work on the BDT Tool involved both using the tool for various critical tasks and improving its functionality to make it more efficient and reliable.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to notion_export_20241106_215738.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Save to file\n",
    "output_file = f\"notion_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Data exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "documents = [Document(text=record['content'], metadata=record['properties']) for record in processed_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='95854c94-20ae-44f9-8540-c8a100de8a15', embedding=None, metadata={'Employer': 'McMaster University - Partnered with Stellantis', 'Description': 'Maintained and improved the  Boundary Diagram Tool  (BDT) for change impact analysis in large-scale Simulink models, specifically for automotive systems at Stellantis   ', 'Project Size': 'Medium', 'When': '2020-06-01', 'Position': 'Research Assistant', 'Tags': ['MATLAB', 'Simulink'], 'Name': 'MATLAB/Simulink - Boundary Diagram Tool', 'header': 'Project Overview:'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The  Boundary Diagram Tool (BDT)  is an advanced tool designed for  change impact analysis  in large-scale Simulink models, particularly those used in embedded systems like automotive control units. The tool enables engineers to trace how changes in specific parts of a system propagate through other models and network interfaces, aiding in software maintenance, debugging, and ensuring compliance with safety standards like  ISO 26262 . It was developed as part of a collaboration with  Stellantis  (formerly FCA), where it played a key role in managing changes within complex automotive systems, such as  hybrid electric vehicle control systems .\\nAs part of the development team, my work on the BDT Tool involved both using the tool for various critical tasks and improving its functionality to make it more efficient and reliable.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
